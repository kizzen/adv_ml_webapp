{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A visual tool to explore adversarial attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although many people fear that the advent of machine learning will unearth the potential destruction of humanity by an artificial superintelligence, there are already existing security issues associated with this scientific discipline that must be faced today. Since 2014, researchers have been unable to solve the adversarial networks problem, which has its roots in the following phenomenon: carefully crafted perturbations, also called adversarial noise, can be applied to the inputs of deep neural networks, forcing them to make false predictions. These adversarial attacks, as they are commonly called, can cause accidents in autonomous cars, or illegal content to bypass Internet filters.\n",
    "\n",
    "This notebook will provide an overview of adversarial attacks and defenses. I will then conclude "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
